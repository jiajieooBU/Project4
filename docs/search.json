[
  {
    "objectID": "skill_gap_analysis.html",
    "href": "skill_gap_analysis.html",
    "title": "Skill Prioritization & Recommendations",
    "section": "",
    "text": "import pandas as pd\nskills_data = {\n    \"Name\": [\"Jiajie Wu\", \"Qilin Zhang\", \"Maihong Xu\"],\n    \"Python\": [1, 2, 2],\n    \"SQL\": [1, 1, 2],\n    \"Machine Learning\": [4, 2, 3],\n    \"Cloud Computing\": [2, 2, 3],\n    \"Leadership\": [3, 2, 2],\n    \"Communication\": [2, 3, 3]\n}\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nCloud Computing\nLeadership\nCommunication\n\n\nName\n\n\n\n\n\n\n\n\n\n\nJiajie Wu\n1\n1\n4\n2\n3\n2\n\n\nQilin Zhang\n2\n1\n2\n2\n2\n3\n\n\nMaihong Xu\n2\n2\n3\n3\n2\n3\n\n\n\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(8, 6))\nsns.heatmap(df_skills, annot=True, cmap=\"coolwarm\", linewidth=2)\nplt.title(\"Team Skill Levels Heatmap\")\nplt.show()\n\n\n\n\n\n\n\n\n\nimport ast\nfrom collections import Counter\n\ndf = pd.read_csv(\"data/clean_lightcast_job_postings.csv\")\ndf['SKILLS_NAME'] = df['SKILLS_NAME'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else [])\nall_skills = [skill for sublist in df['SKILLS_NAME'] for skill in sublist]\nskill_counts = Counter(all_skills)\ntop_skills = skill_counts.most_common(10)\n\nprint(top_skills)\n\n[('Communication', 30389), ('Data Analysis', 27153), ('Management', 23542), ('SQL (Programming Language)', 20744), ('Problem Solving', 17738), ('Leadership', 16796), ('Computer Science', 16366), ('Operations', 14008), ('Project Management', 13110), ('Business Process', 12464)]\n\n\n\ntop_skills = [skill for skill, count in top_skills]\ntop_skills\n\n['Communication',\n 'Data Analysis',\n 'Management',\n 'SQL (Programming Language)',\n 'Problem Solving',\n 'Leadership',\n 'Computer Science',\n 'Operations',\n 'Project Management',\n 'Business Process']\n\n\n\n#top_skills = [\"Python\", \"SQL\", \"Machine Learning\", \"Cloud Computing\"]\ntop_skills = ['Communication',\n 'Data Analysis',\n 'Management',\n 'SQL',\n 'Problem Solving',\n 'Leadership',\n 'Computer Science',\n 'Operations',\n 'Project Management',\n 'Business Process']\njob_skill_counts = Counter(top_skills)\n\nfor skill in top_skills:\n    if skill not in df_skills.columns:\n        df_skills[skill] = 0 \ndf_skills\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nCloud Computing\nLeadership\nCommunication\nData Analysis\nManagement\nProblem Solving\nComputer Science\nOperations\nProject Management\nBusiness Process\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJiajie Wu\n1\n1\n4\n2\n3\n2\n0\n0\n0\n0\n0\n0\n0\n\n\nQilin Zhang\n2\n1\n2\n2\n2\n3\n0\n0\n0\n0\n0\n0\n0\n\n\nMaihong Xu\n2\n2\n3\n3\n2\n3\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\n\nIdentifying Skill Gaps & Priorities\n\n\n\n\n\n\n\n\nName\nStrengths\nAreas for Improvement\n\n\n\n\nJiajie Wu\nMachine Learning (4), Cloud Computing (2)\nPython (1), SQL (1), Leadership (3), Communication (2)\n\n\nQilin Zhang\nPython (2), SQL (1), Cloud Computing (2)\nMachine Learning (2), Leadership (2), Communication (3)\n\n\nMaihong Xu\nPython (2), SQL (2), Machine Learning (3), Cloud Computing (3)\nLeadership (2), Communication (3)\n\n\n\n\nTop priority for all: Leadership & Communication (soft skills critical for collaboration).\n\nJiajie Wu: Needs Python & SQL improvement for foundational data work.\n\nQilin Zhang: Needs Machine Learning improvement to complement data skills.\n\nMaihong Xu: Should improve Leadership & Communication to be well-rounded.\n\n\n\n\nRecommended Courses & Resources\nPython & SQL (For Jiajie Wu)\n- Python for Everybody (Coursera - University of Michigan)\n- SQL for Data Science (UC Davis)\nMachine Learning (For Qilin Zhang)\n- Machine Learning (Andrew Ng - Coursera)\nLeadership & Communication (For All)\n- Leadership & Communication (Harvard Business School)\n\n\n\nTeam Collaboration to Bridge Gaps\nüîπ ‚ÄúSkill Swap‚Äù Sessions: Each member teaches their strongest skill to others. Example:\n- Jiajie Wu teaches Machine Learning.\n- Qilin Zhang leads an SQL deep dive.\n- Maihong Xu organizes a Cloud Computing workshop.\nüîπ Pair Projects: Work together on real-world projects that force skill improvement.\n- Build a data pipeline: Jiajie focuses on Python, Qilin on SQL, Maihong on Cloud.\n- Solve a business problem using ML models (Kaggle, Hackathons)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "del/analytics.html",
    "href": "del/analytics.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "# Cell 1: Import libraries and initialize Spark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import DoubleType, StringType, IntegerType, BooleanType, FloatType\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import PCA\nimport pandas as pd\nimport numpy as np\nimport os\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\nfrom sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n\npio.templates.default = \"plotly_white\"\n\nif not os.path.exists('_output'):\n    os.makedirs('_output')\n\nspark = SparkSession.builder \\\n    .appName(\"AI_Career_Analysis\") \\\n    .config(\"spark.driver.memory\", \"4g\") \\\n    .config(\"spark.sql.debug.maxToStringFields\", 100) \\\n    .getOrCreate()\n\n\n# Cell 2: Load data and select columns\ndf = spark.read.option(\"header\", \"true\") \\\n              .option(\"inferSchema\", \"true\") \\\n              .option(\"multiLine\",\"true\") \\\n              .option(\"escape\", \"\\\"\") \\\n              .csv(\"./data/lightcast_job_postings.csv\")\n\nuseful_columns = [\n    'COMPANY_IS_STAFFING',\n    'MIN_EDULEVELS_NAME',\n    'EMPLOYMENT_TYPE_NAME',\n    'MIN_YEARS_EXPERIENCE',\n    'MAX_YEARS_EXPERIENCE',\n    'IS_INTERNSHIP',\n    'SALARY',\n    'REMOTE_TYPE_NAME', \n    'STATE_NAME',\n    'NAICS2_NAME',\n    'LOT_V6_SPECIALIZED_OCCUPATION_NAME',\n    'SKILLS_NAME',\n    'LIGHTCAST_SECTORS_NAME',\n]\n\ndf_selected = df.select(*useful_columns)\n\ndf_selected = df_selected.withColumn(\n    \"AI\", \n    F.when(F.col(\"LIGHTCAST_SECTORS_NAME\").contains(\"Artificial Intelligence\"), True).otherwise(False)\n)\n\n\n# Cell 3: Data cleaning\ndf_clean = df_selected\n\nnumeric_cols = ['MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'SALARY']\nfor col in numeric_cols:\n    median_val = df_clean.agg(F.median(col).alias(f\"median_{col}\")).collect()[0][f\"median_{col}\"]\n    df_clean = df_clean.withColumn(col, F.when(F.col(col).isNull(), median_val).otherwise(F.col(col)))\n\nboolean_cols = []\nstring_cols = []\n\nfor col in useful_columns:\n    if col in numeric_cols:\n        continue\n    \n    col_type = df_clean.schema[col].dataType\n    if isinstance(col_type, BooleanType):\n        boolean_cols.append(col)\n    else:\n        string_cols.append(col)\n\nfor col in string_cols:\n    df_clean = df_clean.withColumn(col, F.when(F.col(col).isNull(), \"No Data\").otherwise(F.col(col)))\n\nfor col in boolean_cols:\n    df_clean = df_clean.withColumn(col, F.when(F.col(col).isNull(), False).otherwise(F.col(col)))\n\n\n# Cell 4: Add skills columns\nselected_skills = [\n    \"Python (Programming Language)\", \"Data Science\", \"Statistics\", \"R (Programming Language)\",\n    \"Mathematics\", \"Data Analysis\", \"SQL (Programming Language)\", \"Computer Science\",\n    \"Data Modeling\", \"Data Visualization\", \"Tableau (Business Intelligence Software)\",\n    \"Power BI\", \"Automation\", \"Research\", \"Business Intelligence\", \"Data Management\",\n    \"Data Warehousing\", \"Microsoft Excel\", \"SAP Applications\", \"Data Quality\"\n]\n\nfor skill in selected_skills:\n    df_clean = df_clean.withColumn(\n        skill.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\"),\n        F.when(F.col(\"SKILLS_NAME\").contains(skill), 1).otherwise(0)\n    )\n\n\n# Cell 5: Convert to pandas for EDA\ndf_pandas = df_clean.toPandas()\n\nfig1 = px.pie(values=df_pandas['AI'].value_counts().values, \n              names=df_pandas['AI'].value_counts().index, \n              title='Distribution of AI vs Non-AI Jobs')\nfig1.write_html(\"_output/ai_distribution.html\")\nfig1.show()\n\nfig2 = px.box(df_pandas, x='AI', y='SALARY', \n              title='Salary Distribution: AI vs Non-AI Jobs')\nfig2.write_html(\"_output/salary_distribution.html\")\nfig2.show()\n\n                                                \n\n\n                                                \n\n\n\n# Cell 6: Industry visualization\nai_industry = df_pandas[df_pandas['AI'] == True]['NAICS2_NAME'].value_counts().nlargest(10).reset_index()\nai_industry.columns = ['Industry', 'Count']\nai_industry['Type'] = 'AI'\n\nnon_ai_industry = df_pandas[df_pandas['AI'] == False]['NAICS2_NAME'].value_counts().nlargest(10).reset_index()\nnon_ai_industry.columns = ['Industry', 'Count']\nnon_ai_industry['Type'] = 'Non-AI'\n\nindustry_df = pd.concat([ai_industry, non_ai_industry])\n\nfig3 = px.bar(industry_df, x='Industry', y='Count', color='Type', barmode='group',\n             title='Top 10 Industries: AI vs Non-AI Jobs')\nfig3.write_html(\"_output/industry_distribution.html\")\nfig3.show()\n\n                                                \n\n\n\n# Cell 7: Job title visualization\nai_titles = df_pandas[df_pandas['AI'] == True]['LOT_V6_SPECIALIZED_OCCUPATION_NAME'].value_counts().nlargest(10).reset_index()\nai_titles.columns = ['Job Title', 'Count']\nai_titles['Type'] = 'AI'\n\nnon_ai_titles = df_pandas[df_pandas['AI'] == False]['LOT_V6_SPECIALIZED_OCCUPATION_NAME'].value_counts().nlargest(10).reset_index()\nnon_ai_titles.columns = ['Job Title', 'Count']\nnon_ai_titles['Type'] = 'Non-AI'\n\ntitles_df = pd.concat([ai_titles, non_ai_titles])\n\nfig4 = px.bar(titles_df, x='Job Title', y='Count', color='Type', barmode='group',\n             title='Top 10 Job Titles: AI vs Non-AI Jobs')\nfig4.write_html(\"_output/job_title_distribution.html\")\nfig4.show()\n\n                                                \n\n\n\n# Cell 8: Skills visualization\nskill_cols = [col for col in df_pandas.columns if any(skill.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\") == col for skill in selected_skills)]\n\nai_skills = df_pandas[df_pandas['AI'] == True][skill_cols].sum().reset_index()\nai_skills.columns = ['Skill', 'Count']\nai_skills['Type'] = 'AI'\n\nnon_ai_skills = df_pandas[df_pandas['AI'] == False][skill_cols].sum().reset_index()\nnon_ai_skills.columns = ['Skill', 'Count']\nnon_ai_skills['Type'] = 'Non-AI'\n\nskills_df = pd.concat([ai_skills, non_ai_skills])\n\nfig5 = px.bar(skills_df, x='Skill', y='Count', color='Type', barmode='group',\n             title='Skills Distribution: AI vs Non-AI Jobs')\nfig5.write_html(\"_output/skills_distribution.html\")\nfig5.show()\n\n                                                \n\n\n\n# Cell 9: KMeans clustering setup\nfeature_cols = [\n    'SALARY',\n    'Python_Programming_Language',\n    'Data_Science',\n    'Statistics',\n    'R_Programming_Language',\n    'Mathematics',\n    'Data_Analysis',\n    'SQL_Programming_Language',\n    'Computer_Science',\n    'Data_Modeling',\n    'Data_Visualization',\n    'Tableau_Business_Intelligence_Software',\n    'Power_BI',\n    'Automation',\n    'Research',\n    'Business_Intelligence',\n    'Data_Management',\n    'Data_Warehousing',\n    'Microsoft_Excel',\n    'SAP_Applications',\n    'Data_Quality'\n]\n\nassembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_unscaled\")\nscaler = StandardScaler(inputCol=\"features_unscaled\", outputCol=\"features\", withStd=True, withMean=True)\n\npipeline = Pipeline(stages=[assembler, scaler])\n\nmodel = pipeline.fit(df_clean)\ndf_transformed = model.transform(df_clean)\n\nkmeans = KMeans(k=2, seed=42, featuresCol=\"features\")\nkmeans_model = kmeans.fit(df_transformed)\n\ndf_with_clusters = kmeans_model.transform(df_transformed)\n\n\n# Cell 10: PCA transformation for visualization\npca = PCA(k=2, inputCol=\"features\", outputCol=\"pca_features\")\npca_model = pca.fit(df_transformed)\ndf_pca = pca_model.transform(df_transformed)\n\ndf_pca_pandas = df_pca.select(\"pca_features\", \"AI\").toPandas()\ndf_clusters_pandas = df_with_clusters.select(\"prediction\").toPandas()\n\ndf_pca_pandas['PCA1'] = df_pca_pandas['pca_features'].apply(lambda x: float(x[0]))\ndf_pca_pandas['PCA2'] = df_pca_pandas['pca_features'].apply(lambda x: float(x[1]))\ndf_pca_pandas['Cluster'] = df_clusters_pandas['prediction']\n\n\n# Cell 11: Cluster visualization\nfig6 = px.scatter(\n    df_pca_pandas, \n    x='PCA1', \n    y='PCA2', \n    color='Cluster',\n    title='KMeans Clustering: PCA Visualization of Job Clusters',\n    labels={'PCA1': 'Principal Component 1', 'PCA2': 'Principal Component 2'},\n    color_discrete_sequence=['#1f77b4', '#ff7f0e']\n)\nfig6.write_html(\"_output/kmeans_clusters.html\")\nfig6.show()\n\nfig7 = px.scatter(\n    df_pca_pandas, \n    x='PCA1', \n    y='PCA2', \n    color='AI',\n    title='AI vs Non-AI Jobs: PCA Visualization',\n    labels={'PCA1': 'Principal Component 1', 'PCA2': 'Principal Component 2'},\n    color_discrete_sequence=['#2ca02c', '#d62728'],\n    category_orders={\"AI\": [True, False]}\n)\nfig7.write_html(\"_output/ai_vs_non_ai_pca.html\")\nfig7.show()\n\n                                                \n\n\n                                                \n\n\n\n# Cell 12: Cluster analysis\ncluster_ai_count = df_pca_pandas.groupby(['Cluster', 'AI']).size().unstack(fill_value=0)\n\ncluster_ai_table = pd.DataFrame({\n    'Cluster': ['Cluster 0', 'Cluster 1'],\n    'AI Jobs': cluster_ai_count[True].values,\n    'Non-AI Jobs': cluster_ai_count[False].values\n})\n\ncluster_ai_table['Total'] = cluster_ai_table['AI Jobs'] + cluster_ai_table['Non-AI Jobs']\ncluster_ai_table['AI %'] = cluster_ai_table['AI Jobs'] / cluster_ai_table['Total'] * 100\ncluster_ai_table['Non-AI %'] = cluster_ai_table['Non-AI Jobs'] / cluster_ai_table['Total'] * 100\n\nfig8 = px.bar(\n    cluster_ai_table,\n    x='Cluster',\n    y=['AI Jobs', 'Non-AI Jobs'],\n    title='Distribution of AI and Non-AI Jobs in Each Cluster',\n    barmode='group'\n)\nfig8.write_html(\"_output/cluster_ai_distribution.html\")\nfig8.show()\n\n                                                \n\n\n\n# Cell 13: Classification preparation\ndf_clean = df_clean.withColumn(\"AI_label\", F.when(F.col(\"AI\") == True, 1.0).otherwise(0.0))\n\nfeature_cols = [\n    'MIN_YEARS_EXPERIENCE',\n    'MAX_YEARS_EXPERIENCE',\n    'SALARY',\n    'Python_Programming_Language',\n    'Data_Science',\n    'Statistics', \n    'R_Programming_Language',\n    'Mathematics',\n    'Data_Analysis',\n    'SQL_Programming_Language',\n    'Computer_Science',\n    'Data_Modeling',\n    'Data_Visualization',\n    'Tableau_Business_Intelligence_Software',\n    'Power_BI',\n    'Automation',\n    'Research',\n    'Business_Intelligence',\n    'Data_Management',\n    'Data_Warehousing',\n    'Microsoft_Excel',\n    'SAP_Applications',\n    'Data_Quality'\n]\n\ncategorical_cols = [\n    'EMPLOYMENT_TYPE_NAME', \n    'REMOTE_TYPE_NAME',\n    'MIN_EDULEVELS_NAME',\n    'STATE_NAME',\n    'NAICS2_NAME',\n    'LOT_V6_SPECIALIZED_OCCUPATION_NAME',\n]\n\ntrain_df, test_df = df_clean.randomSplit([0.8, 0.2], seed=42)\n\n\n# Cell 14: Logistic Regression model\nindexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\") for col in categorical_cols]\nencoders = [OneHotEncoder(inputCol=f\"{col}_indexed\", outputCol=f\"{col}_encoded\") for col in categorical_cols]\nencoded_cols = [f\"{col}_encoded\" for col in categorical_cols]\n\nassembler = VectorAssembler(inputCols=feature_cols + encoded_cols, outputCol=\"features\")\nlr = LogisticRegression(featuresCol=\"features\", labelCol=\"AI_label\", maxIter=10, regParam=0.01)\nlr_pipeline = Pipeline(stages=indexers + encoders + [assembler, lr])\n\nlr_model = lr_pipeline.fit(train_df)\nlr_predictions = lr_model.transform(test_df)\n\nevaluator = BinaryClassificationEvaluator(labelCol=\"AI_label\", rawPredictionCol=\"rawPrediction\")\naccuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"AI_label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n\nlr_accuracy = accuracy_evaluator.evaluate(lr_predictions)\nlr_auroc = evaluator.evaluate(lr_predictions)\n\nprint(f\"Logistic Regression - Accuracy: {lr_accuracy:.3f}, AUC: {lr_auroc:.3f}\")\n\nLogistic Regression - Accuracy: 0.886, AUC: 0.819\n\n\n\n# Cell 15: Random Forest model\nrf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"AI_label\", numTrees=100, maxDepth=10, seed=42)\nrf_pipeline = Pipeline(stages=indexers + encoders + [assembler, rf])\n\nrf_model = rf_pipeline.fit(train_df)\nrf_predictions = rf_model.transform(test_df)\n\nrf_accuracy = accuracy_evaluator.evaluate(rf_predictions)\nrf_auroc = evaluator.evaluate(rf_predictions)\n\nprint(f\"Random Forest - Accuracy: {rf_accuracy:.3f}, AUC: {rf_auroc:.3f}\")\n\nRandom Forest - Accuracy: 0.900, AUC: 0.867\n\n\n\n# Cell 16: Logistic Regression evaluation\nlr_pred_pandas = lr_predictions.select(\"AI_label\", \"prediction\", \"probability\").toPandas()\n\nlr_cm = confusion_matrix(lr_pred_pandas[\"AI_label\"], lr_pred_pandas[\"prediction\"])\n\nlr_precision, lr_recall, lr_f1, _ = precision_recall_fscore_support(\n    lr_pred_pandas[\"AI_label\"], \n    lr_pred_pandas[\"prediction\"], \n    average='binary'\n)\n\nlr_fpr, lr_tpr, _ = roc_curve(\n    lr_pred_pandas[\"AI_label\"], \n    lr_pred_pandas[\"probability\"].apply(lambda x: float(x[1]))\n)\nlr_auc = auc(lr_fpr, lr_tpr)\n\nprint(f\"Logistic Regression Metrics:\")\nprint(f\"Precision: {lr_precision:.3f}\")\nprint(f\"Recall: {lr_recall:.3f}\")\nprint(f\"F1 Score: {lr_f1:.3f}\")\nprint(f\"AUC: {lr_auc:.3f}\")\n\nfig9 = px.imshow(\n    lr_cm,\n    text_auto=True,\n    labels=dict(x=\"Predicted\", y=\"Actual\"),\n    x=['Non-AI', 'AI'],\n    y=['Non-AI', 'AI'],\n    title='Logistic Regression Confusion Matrix',\n    color_continuous_scale='Blues'\n)\nfig9.write_html(\"_output/lr_confusion_matrix.html\")\nfig9.show()\n\nLogistic Regression Metrics:\nPrecision: 0.589\nRecall: 0.211\nF1 Score: 0.311\nAUC: 0.819\n\n\n                                                \n\n\n\n# Cell 17: Random Forest evaluation\nrf_pred_pandas = rf_predictions.select(\"AI_label\", \"prediction\", \"probability\").toPandas()\n\nrf_cm = confusion_matrix(rf_pred_pandas[\"AI_label\"], rf_pred_pandas[\"prediction\"])\n\nrf_precision, rf_recall, rf_f1, _ = precision_recall_fscore_support(\n    rf_pred_pandas[\"AI_label\"], \n    rf_pred_pandas[\"prediction\"], \n    average='binary'\n)\n\nrf_fpr, rf_tpr, _ = roc_curve(\n    rf_pred_pandas[\"AI_label\"], \n    rf_pred_pandas[\"probability\"].apply(lambda x: float(x[1]))\n)\nrf_auc = auc(rf_fpr, rf_tpr)\n\nprint(f\"Random Forest Metrics:\")\nprint(f\"Precision: {rf_precision:.3f}\")\nprint(f\"Recall: {rf_recall:.3f}\")\nprint(f\"F1 Score: {rf_f1:.3f}\")\nprint(f\"AUC: {rf_auc:.3f}\")\n\nfig10 = px.imshow(\n    rf_cm,\n    text_auto=True,\n    labels=dict(x=\"Predicted\", y=\"Actual\"),\n    x=['Non-AI', 'AI'],\n    y=['Non-AI', 'AI'],\n    title='Random Forest Confusion Matrix',\n    color_continuous_scale='Greens'\n)\nfig10.write_html(\"_output/rf_confusion_matrix.html\")\nfig10.show()\n\nRandom Forest Metrics:\nPrecision: 0.958\nRecall: 0.190\nF1 Score: 0.318\nAUC: 0.867\n\n\n                                                \n\n\n\n# Cell 18: ROC Curve comparison\nfig11 = go.Figure()\n\nfig11.add_trace(go.Scatter(\n    x=lr_fpr,\n    y=lr_tpr,\n    name=f'Logistic Regression (AUC = {lr_auc:.3f})',\n    mode='lines'\n))\n\nfig11.add_trace(go.Scatter(\n    x=rf_fpr,\n    y=rf_tpr,\n    name=f'Random Forest (AUC = {rf_auc:.3f})',\n    mode='lines'\n))\n\nfig11.add_trace(go.Scatter(\n    x=[0, 1],\n    y=[0, 1],\n    mode='lines',\n    name='Random',\n    line=dict(dash='dash')\n))\n\nfig11.update_layout(\n    title='ROC Curves for AI Job Classification',\n    xaxis=dict(title='False Positive Rate'),\n    yaxis=dict(title='True Positive Rate'),\n    legend=dict(x=0.1, y=0.9)\n)\n\nfig11.write_html(\"_output/roc_curves.html\")\nfig11.show()\n\n                                                \n\n\n\n# Cell 19: Model comparison table\nmetrics_df = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Random Forest'],\n    'Accuracy': [lr_accuracy, rf_accuracy],\n    'Precision': [lr_precision, rf_precision],\n    'Recall': [lr_recall, rf_recall],\n    'F1 Score': [lr_f1, rf_f1],\n    'AUC': [lr_auc, rf_auc]\n})\n\nfig12 = go.Figure(data=[go.Table(\n    header=dict(\n        values=list(metrics_df.columns),\n        fill_color='paleturquoise',\n        align='left'\n    ),\n    cells=dict(\n        values=[metrics_df[col] for col in metrics_df.columns],\n        fill_color='lavender',\n        align='left',\n        format=[None, '.3f', '.3f', '.3f', '.3f', '.3f']\n    )\n)])\n\nfig12.update_layout(title='Classification Metrics Comparison')\nfig12.write_html(\"_output/metrics_comparison.html\")\nfig12.show()"
  },
  {
    "objectID": "analytics.html",
    "href": "analytics.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "# Cell 1: Import libraries and initialize Spark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import DoubleType, StringType, IntegerType, BooleanType, FloatType\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import PCA\nimport pandas as pd\nimport numpy as np\nimport os\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\nfrom sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n\npio.templates.default = \"plotly_white\"\n\nif not os.path.exists('_output'):\n    os.makedirs('_output')\n\nspark = SparkSession.builder \\\n    .appName(\"AI_Career_Analysis\") \\\n    .config(\"spark.driver.memory\", \"4g\") \\\n    .config(\"spark.sql.debug.maxToStringFields\", 100) \\\n    .getOrCreate()\n\n\n# Cell 2: Load data and select columns\ndf = spark.read.option(\"header\", \"true\") \\\n              .option(\"inferSchema\", \"true\") \\\n              .option(\"multiLine\",\"true\") \\\n              .option(\"escape\", \"\\\"\") \\\n              .csv(\"./data/lightcast_job_postings.csv\")\n\nuseful_columns = [\n    'COMPANY_IS_STAFFING',\n    'MIN_EDULEVELS_NAME',\n    'EMPLOYMENT_TYPE_NAME',\n    'MIN_YEARS_EXPERIENCE',\n    'MAX_YEARS_EXPERIENCE',\n    'IS_INTERNSHIP',\n    'SALARY',\n    'REMOTE_TYPE_NAME', \n    'STATE_NAME',\n    'NAICS2_NAME',\n    'LOT_V6_SPECIALIZED_OCCUPATION_NAME',\n    'SKILLS_NAME',\n    'LIGHTCAST_SECTORS_NAME',\n]\n\ndf_selected = df.select(*useful_columns)\n\ndf_selected = df_selected.withColumn(\n    \"AI\", \n    F.when(F.col(\"LIGHTCAST_SECTORS_NAME\").contains(\"Artificial Intelligence\"), True).otherwise(False)\n)\n\n\n# Cell 3: Data cleaning\ndf_clean = df_selected\n\nnumeric_cols = ['MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'SALARY']\nfor col in numeric_cols:\n    median_val = df_clean.agg(F.median(col).alias(f\"median_{col}\")).collect()[0][f\"median_{col}\"]\n    df_clean = df_clean.withColumn(col, F.when(F.col(col).isNull(), median_val).otherwise(F.col(col)))\n\nboolean_cols = []\nstring_cols = []\n\nfor col in useful_columns:\n    if col in numeric_cols:\n        continue\n    \n    col_type = df_clean.schema[col].dataType\n    if isinstance(col_type, BooleanType):\n        boolean_cols.append(col)\n    else:\n        string_cols.append(col)\n\nfor col in string_cols:\n    df_clean = df_clean.withColumn(col, F.when(F.col(col).isNull(), \"No Data\").otherwise(F.col(col)))\n\nfor col in boolean_cols:\n    df_clean = df_clean.withColumn(col, F.when(F.col(col).isNull(), False).otherwise(F.col(col)))\n\n\n# Cell 4: Add skills columns\nselected_skills = [\n    \"Python (Programming Language)\", \"Data Science\", \"Statistics\", \"R (Programming Language)\",\n    \"Mathematics\", \"Data Analysis\", \"SQL (Programming Language)\", \"Computer Science\",\n    \"Data Modeling\", \"Data Visualization\", \"Tableau (Business Intelligence Software)\",\n    \"Power BI\", \"Automation\", \"Research\", \"Business Intelligence\", \"Data Management\",\n    \"Data Warehousing\", \"Microsoft Excel\", \"SAP Applications\", \"Data Quality\"\n]\n\nfor skill in selected_skills:\n    df_clean = df_clean.withColumn(\n        skill.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\"),\n        F.when(F.col(\"SKILLS_NAME\").contains(skill), 1).otherwise(0)\n    )\n\n\n# Cell 5: Convert to pandas for EDA\ndf_pandas = df_clean.toPandas()\n\nfig1 = px.pie(values=df_pandas['AI'].value_counts().values, \n              names=df_pandas['AI'].value_counts().index, \n              title='Distribution of AI vs Non-AI Jobs')\nfig1.write_html(\"_output/ai_distribution.html\")\nfig1.show()\n\nfig2 = px.box(df_pandas, x='AI', y='SALARY', \n              title='Salary Distribution: AI vs Non-AI Jobs')\nfig2.write_html(\"_output/salary_distribution.html\")\nfig2.show()\n\n                                                \n\n\n                                                \n\n\nLooking at the provided figures, a significant trend emerges in the job market where AI-related positions make up only 12.1% of all job postings, indicating AI remains a specialized sector despite growing industry attention. The salary boxplot reveals that while both AI and non-AI jobs have similar median compensation, AI jobs show a more compressed salary distribution with fewer outliers at the extreme high end compared to non-AI positions, which demonstrate greater salary variance with some positions reaching up to $500,000.\n\n# Cell 6: Industry visualization\nai_industry = df_pandas[df_pandas['AI'] == True]['NAICS2_NAME'].value_counts().nlargest(10).reset_index()\nai_industry.columns = ['Industry', 'Count']\nai_industry['Type'] = 'AI'\n\nnon_ai_industry = df_pandas[df_pandas['AI'] == False]['NAICS2_NAME'].value_counts().nlargest(10).reset_index()\nnon_ai_industry.columns = ['Industry', 'Count']\nnon_ai_industry['Type'] = 'Non-AI'\n\nindustry_df = pd.concat([ai_industry, non_ai_industry])\n\nfig3 = px.bar(industry_df, x='Industry', y='Count', color='Type', barmode='group',\n             title='Top 10 Industries: AI vs Non-AI Jobs')\nfig3.write_html(\"_output/industry_distribution.html\")\nfig3.show()\n\n                                                \n\n\nThe Professional, Scientific, and Technical Services sector dominates both AI and non-AI job listings, but while this industry has approximately 20,000 non-AI positions, it shows a much smaller proportion of AI jobs (around 3,000), indicating that even in tech-heavy industries, AI-specific roles remain a specialized minority compared to traditional positions.\n\n# Cell 7: Job title visualization\nai_titles = df_pandas[df_pandas['AI'] == True]['LOT_V6_SPECIALIZED_OCCUPATION_NAME'].value_counts().nlargest(10).reset_index()\nai_titles.columns = ['Job Title', 'Count']\nai_titles['Type'] = 'AI'\n\nnon_ai_titles = df_pandas[df_pandas['AI'] == False]['LOT_V6_SPECIALIZED_OCCUPATION_NAME'].value_counts().nlargest(10).reset_index()\nnon_ai_titles.columns = ['Job Title', 'Count']\nnon_ai_titles['Type'] = 'Non-AI'\n\ntitles_df = pd.concat([ai_titles, non_ai_titles])\n\nfig4 = px.bar(titles_df, x='Job Title', y='Count', color='Type', barmode='group',\n             title='Top 10 Job Titles: AI vs Non-AI Jobs')\nfig4.write_html(\"_output/job_title_distribution.html\")\nfig4.show()\n\n                                                \n\n\nFor job titles, Data Analyst positions dominate both AI and non-AI sectors, but the proportion of AI Data Analyst roles is significantly higher relative to other AI positions, suggesting this role serves as a common entry point into AI-focused careers.\n\n# Cell 8: Skills visualization\nskill_cols = [col for col in df_pandas.columns if any(skill.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\") == col for skill in selected_skills)]\n\nai_skills = df_pandas[df_pandas['AI'] == True][skill_cols].sum().reset_index()\nai_skills.columns = ['Skill', 'Count']\nai_skills['Type'] = 'AI'\n\nnon_ai_skills = df_pandas[df_pandas['AI'] == False][skill_cols].sum().reset_index()\nnon_ai_skills.columns = ['Skill', 'Count']\nnon_ai_skills['Type'] = 'Non-AI'\n\nskills_df = pd.concat([ai_skills, non_ai_skills])\n\nfig5 = px.bar(skills_df, x='Skill', y='Count', color='Type', barmode='group',\n             title='Skills Distribution: AI vs Non-AI Jobs')\nfig5.write_html(\"_output/skills_distribution.html\")\nfig5.show()\n\n                                                \n\n\nIn the skills distribution chart, technical skills like Python, Data Analysis, and SQL are consistently required across both job categories, though AI positions show a notably higher demand for Python programming specifically, indicating its central importance in AI development workflows.\n\n# Cell 9: KMeans clustering setup\nfeature_cols = [\n    'SALARY',\n    'Python_Programming_Language',\n    'Data_Science',\n    'Statistics',\n    'R_Programming_Language',\n    'Mathematics',\n    'Data_Analysis',\n    'SQL_Programming_Language',\n    'Computer_Science',\n    'Data_Modeling',\n    'Data_Visualization',\n    'Tableau_Business_Intelligence_Software',\n    'Power_BI',\n    'Automation',\n    'Research',\n    'Business_Intelligence',\n    'Data_Management',\n    'Data_Warehousing',\n    'Microsoft_Excel',\n    'SAP_Applications',\n    'Data_Quality'\n]\n\nassembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_unscaled\")\nscaler = StandardScaler(inputCol=\"features_unscaled\", outputCol=\"features\", withStd=True, withMean=True)\n\npipeline = Pipeline(stages=[assembler, scaler])\n\nmodel = pipeline.fit(df_clean)\ndf_transformed = model.transform(df_clean)\n\nkmeans = KMeans(k=2, seed=42, featuresCol=\"features\")\nkmeans_model = kmeans.fit(df_transformed)\n\ndf_with_clusters = kmeans_model.transform(df_transformed)\n\n\n# Cell 10: PCA transformation for visualization\npca = PCA(k=2, inputCol=\"features\", outputCol=\"pca_features\")\npca_model = pca.fit(df_transformed)\ndf_pca = pca_model.transform(df_transformed)\n\ndf_pca_pandas = df_pca.select(\"pca_features\", \"AI\").toPandas()\ndf_clusters_pandas = df_with_clusters.select(\"prediction\").toPandas()\n\ndf_pca_pandas['PCA1'] = df_pca_pandas['pca_features'].apply(lambda x: float(x[0]))\ndf_pca_pandas['PCA2'] = df_pca_pandas['pca_features'].apply(lambda x: float(x[1]))\ndf_pca_pandas['Cluster'] = df_clusters_pandas['prediction']\n\n\n# Cell 11: Cluster visualization\nfig6 = px.scatter(\n    df_pca_pandas, \n    x='PCA1', \n    y='PCA2', \n    color='Cluster',\n    title='KMeans Clustering: PCA Visualization of Job Clusters',\n    labels={'PCA1': 'Principal Component 1', 'PCA2': 'Principal Component 2'},\n    color_discrete_sequence=['#1f77b4', '#ff7f0e']\n)\nfig6.write_html(\"_output/kmeans_clusters.html\")\nfig6.show()\n\nfig7 = px.scatter(\n    df_pca_pandas, \n    x='PCA1', \n    y='PCA2', \n    color='AI',\n    title='AI vs Non-AI Jobs: PCA Visualization',\n    labels={'PCA1': 'Principal Component 1', 'PCA2': 'Principal Component 2'},\n    color_discrete_sequence=['#2ca02c', '#d62728'],\n    category_orders={\"AI\": [True, False]}\n)\nfig7.write_html(\"_output/ai_vs_non_ai_pca.html\")\nfig7.show()\n\n                                                \n\n\n                                                \n\n\nThe KMeans clustering visualization reveals two distinct clusters in the job market data, with Cluster 1 (shown in yellow in the first image) concentrated on the left side of the PCA space and Cluster 0 (dark blue) dominating the right side, suggesting fundamental differences in job characteristics between these groups. The second PCA visualization colorized by AI vs Non-AI shows that while AI jobs (green) are distributed throughout the feature space, they appear slightly more concentrated in the right portion of the plot, particularly at higher values of Principal Component 1, indicating AI positions may have some distinctive feature combinations.\n\n# Cell 12: Cluster analysis\ncluster_ai_count = df_pca_pandas.groupby(['Cluster', 'AI']).size().unstack(fill_value=0)\n\ncluster_ai_table = pd.DataFrame({\n    'Cluster': ['Cluster 0', 'Cluster 1'],\n    'AI Jobs': cluster_ai_count[True].values,\n    'Non-AI Jobs': cluster_ai_count[False].values\n})\n\ncluster_ai_table['Total'] = cluster_ai_table['AI Jobs'] + cluster_ai_table['Non-AI Jobs']\ncluster_ai_table['AI %'] = cluster_ai_table['AI Jobs'] / cluster_ai_table['Total'] * 100\ncluster_ai_table['Non-AI %'] = cluster_ai_table['Non-AI Jobs'] / cluster_ai_table['Total'] * 100\n\nfig8 = px.bar(\n    cluster_ai_table,\n    x='Cluster',\n    y=['AI Jobs', 'Non-AI Jobs'],\n    title='Distribution of AI and Non-AI Jobs in Each Cluster',\n    barmode='group'\n)\nfig8.write_html(\"_output/cluster_ai_distribution.html\")\nfig8.show()\n\n                                                \n\n\nThe bar chart quantifies this distribution, showing that while both clusters contain AI and non-AI positions, Cluster 1 has a dramatically higher proportion of non-AI jobs (approximately 50,000 non-AI vs 3,000 AI positions) compared to Cluster 0, which has a more balanced ratio despite still having more non-AI than AI roles.\n\n# Cell 13: Classification preparation\ndf_clean = df_clean.withColumn(\"AI_label\", F.when(F.col(\"AI\") == True, 1.0).otherwise(0.0))\n\nfeature_cols = [\n    'MIN_YEARS_EXPERIENCE',\n    'MAX_YEARS_EXPERIENCE',\n    'SALARY',\n    'Python_Programming_Language',\n    'Data_Science',\n    'Statistics', \n    'R_Programming_Language',\n    'Mathematics',\n    'Data_Analysis',\n    'SQL_Programming_Language',\n    'Computer_Science',\n    'Data_Modeling',\n    'Data_Visualization',\n    'Tableau_Business_Intelligence_Software',\n    'Power_BI',\n    'Automation',\n    'Research',\n    'Business_Intelligence',\n    'Data_Management',\n    'Data_Warehousing',\n    'Microsoft_Excel',\n    'SAP_Applications',\n    'Data_Quality'\n]\n\ncategorical_cols = [\n    'EMPLOYMENT_TYPE_NAME', \n    'REMOTE_TYPE_NAME',\n    'MIN_EDULEVELS_NAME',\n    'STATE_NAME',\n    'NAICS2_NAME',\n    'LOT_V6_SPECIALIZED_OCCUPATION_NAME',\n]\n\ntrain_df, test_df = df_clean.randomSplit([0.8, 0.2], seed=42)\n\n\n# Cell 14: Logistic Regression model\nindexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\") for col in categorical_cols]\nencoders = [OneHotEncoder(inputCol=f\"{col}_indexed\", outputCol=f\"{col}_encoded\") for col in categorical_cols]\nencoded_cols = [f\"{col}_encoded\" for col in categorical_cols]\n\nassembler = VectorAssembler(inputCols=feature_cols + encoded_cols, outputCol=\"features\")\nlr = LogisticRegression(featuresCol=\"features\", labelCol=\"AI_label\", maxIter=10, regParam=0.01)\nlr_pipeline = Pipeline(stages=indexers + encoders + [assembler, lr])\n\nlr_model = lr_pipeline.fit(train_df)\nlr_predictions = lr_model.transform(test_df)\n\nevaluator = BinaryClassificationEvaluator(labelCol=\"AI_label\", rawPredictionCol=\"rawPrediction\")\naccuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"AI_label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n\nlr_accuracy = accuracy_evaluator.evaluate(lr_predictions)\nlr_auroc = evaluator.evaluate(lr_predictions)\n\nprint(f\"Logistic Regression - Accuracy: {lr_accuracy:.3f}, AUC: {lr_auroc:.3f}\")\n\nLogistic Regression - Accuracy: 0.886, AUC: 0.819\n\n\n\n# Cell 15: Random Forest model\nrf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"AI_label\", numTrees=100, maxDepth=10, seed=42)\nrf_pipeline = Pipeline(stages=indexers + encoders + [assembler, rf])\n\nrf_model = rf_pipeline.fit(train_df)\nrf_predictions = rf_model.transform(test_df)\n\nrf_accuracy = accuracy_evaluator.evaluate(rf_predictions)\nrf_auroc = evaluator.evaluate(rf_predictions)\n\nprint(f\"Random Forest - Accuracy: {rf_accuracy:.3f}, AUC: {rf_auroc:.3f}\")\n\nRandom Forest - Accuracy: 0.900, AUC: 0.867\n\n\n\n# Cell 16: Logistic Regression evaluation\nlr_pred_pandas = lr_predictions.select(\"AI_label\", \"prediction\", \"probability\").toPandas()\n\nlr_cm = confusion_matrix(lr_pred_pandas[\"AI_label\"], lr_pred_pandas[\"prediction\"])\n\nlr_precision, lr_recall, lr_f1, _ = precision_recall_fscore_support(\n    lr_pred_pandas[\"AI_label\"], \n    lr_pred_pandas[\"prediction\"], \n    average='binary'\n)\n\nlr_fpr, lr_tpr, _ = roc_curve(\n    lr_pred_pandas[\"AI_label\"], \n    lr_pred_pandas[\"probability\"].apply(lambda x: float(x[1]))\n)\nlr_auc = auc(lr_fpr, lr_tpr)\n\nprint(f\"Logistic Regression Metrics:\")\nprint(f\"Precision: {lr_precision:.3f}\")\nprint(f\"Recall: {lr_recall:.3f}\")\nprint(f\"F1 Score: {lr_f1:.3f}\")\nprint(f\"AUC: {lr_auc:.3f}\")\n\nfig9 = px.imshow(\n    lr_cm,\n    text_auto=True,\n    labels=dict(x=\"Predicted\", y=\"Actual\"),\n    x=['Non-AI', 'AI'],\n    y=['Non-AI', 'AI'],\n    title='Logistic Regression Confusion Matrix',\n    color_continuous_scale='Blues'\n)\nfig9.write_html(\"_output/lr_confusion_matrix.html\")\nfig9.show()\n\nLogistic Regression Metrics:\nPrecision: 0.589\nRecall: 0.211\nF1 Score: 0.311\nAUC: 0.819\n\n\n                                                \n\n\nLogistic Regression: While demonstrating a decent overall ability to distinguish between classes (AUC=0.819), the Logistic Regression model struggles to correctly identify actual AI jobs (low recall of 0.211), although the jobs it does predict as AI are correct about 59% of the time.\n\n# Cell 17: Random Forest evaluation\nrf_pred_pandas = rf_predictions.select(\"AI_label\", \"prediction\", \"probability\").toPandas()\n\nrf_cm = confusion_matrix(rf_pred_pandas[\"AI_label\"], rf_pred_pandas[\"prediction\"])\n\nrf_precision, rf_recall, rf_f1, _ = precision_recall_fscore_support(\n    rf_pred_pandas[\"AI_label\"], \n    rf_pred_pandas[\"prediction\"], \n    average='binary'\n)\n\nrf_fpr, rf_tpr, _ = roc_curve(\n    rf_pred_pandas[\"AI_label\"], \n    rf_pred_pandas[\"probability\"].apply(lambda x: float(x[1]))\n)\nrf_auc = auc(rf_fpr, rf_tpr)\n\nprint(f\"Random Forest Metrics:\")\nprint(f\"Precision: {rf_precision:.3f}\")\nprint(f\"Recall: {rf_recall:.3f}\")\nprint(f\"F1 Score: {rf_f1:.3f}\")\nprint(f\"AUC: {rf_auc:.3f}\")\n\nfig10 = px.imshow(\n    rf_cm,\n    text_auto=True,\n    labels=dict(x=\"Predicted\", y=\"Actual\"),\n    x=['Non-AI', 'AI'],\n    y=['Non-AI', 'AI'],\n    title='Random Forest Confusion Matrix',\n    color_continuous_scale='Greens'\n)\nfig10.write_html(\"_output/rf_confusion_matrix.html\")\nfig10.show()\n\nRandom Forest Metrics:\nPrecision: 0.958\nRecall: 0.190\nF1 Score: 0.318\nAUC: 0.867\n\n\n                                                \n\n\nRandom Forest: The Random Forest model is highly precise when predicting AI jobs (Precision=0.958) but identifies an even smaller fraction of the true AI jobs compared to logistic regression (very low recall of 0.190), despite having a better overall discriminatory power (AUC=0.867).\n\n# Cell 18: ROC Curve comparison\nfig11 = go.Figure()\n\nfig11.add_trace(go.Scatter(\n    x=lr_fpr,\n    y=lr_tpr,\n    name=f'Logistic Regression (AUC = {lr_auc:.3f})',\n    mode='lines'\n))\n\nfig11.add_trace(go.Scatter(\n    x=rf_fpr,\n    y=rf_tpr,\n    name=f'Random Forest (AUC = {rf_auc:.3f})',\n    mode='lines'\n))\n\nfig11.add_trace(go.Scatter(\n    x=[0, 1],\n    y=[0, 1],\n    mode='lines',\n    name='Random',\n    line=dict(dash='dash')\n))\n\nfig11.update_layout(\n    title='ROC Curves for AI Job Classification',\n    xaxis=dict(title='False Positive Rate'),\n    yaxis=dict(title='True Positive Rate'),\n    legend=dict(x=0.1, y=0.9)\n)\n\nfig11.write_html(\"_output/roc_curves.html\")\nfig11.show()\n\n                                                \n\n\nThe ROC curves visually confirm that Random Forest (AUC=0.867) has a better overall performance in distinguishing between AI and Non-AI jobs than Logistic Regression (AUC=0.819), achieving higher true positive rates for similar false positive rates across various thresholds.\n\n# Cell 19: Model comparison table\nmetrics_df = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Random Forest'],\n    'Accuracy': [lr_accuracy, rf_accuracy],\n    'Precision': [lr_precision, rf_precision],\n    'Recall': [lr_recall, rf_recall],\n    'F1 Score': [lr_f1, rf_f1],\n    'AUC': [lr_auc, rf_auc]\n})\n\nfig12 = go.Figure(data=[go.Table(\n    header=dict(\n        values=list(metrics_df.columns),\n        fill_color='paleturquoise',\n        align='left'\n    ),\n    cells=dict(\n        values=[metrics_df[col] for col in metrics_df.columns],\n        fill_color='lavender',\n        align='left',\n        format=[None, '.3f', '.3f', '.3f', '.3f', '.3f']\n    )\n)])\n\nfig12.update_layout(title='Classification Metrics Comparison')\nfig12.write_html(\"_output/metrics_comparison.html\")\nfig12.show()\n\n                                                \n\n\nThis table summarizes that while Random Forest achieves higher overall accuracy, precision, and AUC compared to Logistic Regression, both models exhibit poor recall and consequently low F1 scores, indicating difficulty in identifying the minority class (AI jobs) effectively despite good overall performance."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "import pandas as pd\n\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")\n\nprint(df.head())\nprint(df.info())\n\n                                         ID LAST_UPDATED_DATE  \\\n0  1f57d95acf4dc67ed2819eb12f049f6a5c11782c          9/6/2024   \n1  0cb072af26757b6c4ea9464472a50a443af681ac          8/2/2024   \n2  85318b12b3331fa490d32ad014379df01855c557          9/6/2024   \n3  1b5c3941e54a1889ef4f8ae55b401a550708a310          9/6/2024   \n4  cb5ca25f02bdf25c13edfede7931508bfd9e858f         6/19/2024   \n\n      LAST_UPDATED_TIMESTAMP  DUPLICATES    POSTED    EXPIRED  DURATION  \\\n0  2024-09-06 20:32:57.352 Z         0.0  6/2/2024   6/8/2024       6.0   \n1  2024-08-02 17:08:58.838 Z         0.0  6/2/2024   8/1/2024       NaN   \n2  2024-09-06 20:32:57.352 Z         1.0  6/2/2024   7/7/2024      35.0   \n3  2024-09-06 20:32:57.352 Z         1.0  6/2/2024  7/20/2024      48.0   \n4  2024-06-19 07:00:00.000 Z         0.0  6/2/2024  6/17/2024      15.0   \n\n             SOURCE_TYPES                                        SOURCES  \\\n0       [\\n  \"Company\"\\n]                        [\\n  \"brassring.com\"\\n]   \n1     [\\n  \"Job Board\"\\n]                            [\\n  \"maine.gov\"\\n]   \n2     [\\n  \"Job Board\"\\n]                           [\\n  \"dejobs.org\"\\n]   \n3     [\\n  \"Job Board\"\\n]  [\\n  \"disabledperson.com\",\\n  \"dejobs.org\"\\n]   \n4  [\\n  \"FreeJobBoard\"\\n]                       [\\n  \"craigslist.org\"\\n]   \n\n                                                 URL  ... NAICS_2022_2  \\\n0  [\\n  \"https://sjobs.brassring.com/TGnewUI/Sear...  ...         44.0   \n1   [\\n  \"https://joblink.maine.gov/jobs/1085740\"\\n]  ...         56.0   \n2  [\\n  \"https://dejobs.org/dallas-tx/data-analys...  ...         52.0   \n3  [\\n  \"https://www.disabledperson.com/jobs/5948...  ...         52.0   \n4  [\\n  \"https://modesto.craigslist.org/sls/77475...  ...         99.0   \n\n                                   NAICS_2022_2_NAME NAICS_2022_3  \\\n0                                       Retail Trade        441.0   \n1  Administrative and Support and Waste Managemen...        561.0   \n2                              Finance and Insurance        524.0   \n3                              Finance and Insurance        522.0   \n4                              Unclassified Industry        999.0   \n\n                              NAICS_2022_3_NAME NAICS_2022_4  \\\n0               Motor Vehicle and Parts Dealers       4413.0   \n1           Administrative and Support Services       5613.0   \n2     Insurance Carriers and Related Activities       5242.0   \n3  Credit Intermediation and Related Activities       5221.0   \n4                         Unclassified Industry       9999.0   \n\n                                   NAICS_2022_4_NAME  NAICS_2022_5  \\\n0  Automotive Parts, Accessories, and Tire Retailers       44133.0   \n1                                Employment Services       56132.0   \n2  Agencies, Brokerages, and Other Insurance Rela...       52429.0   \n3                   Depository Credit Intermediation       52211.0   \n4                              Unclassified Industry       99999.0   \n\n                            NAICS_2022_5_NAME NAICS_2022_6  \\\n0  Automotive Parts and Accessories Retailers     441330.0   \n1                     Temporary Help Services     561320.0   \n2          Other Insurance Related Activities     524291.0   \n3                          Commercial Banking     522110.0   \n4                       Unclassified Industry     999999.0   \n\n                            NAICS_2022_6_NAME  \n0  Automotive Parts and Accessories Retailers  \n1                     Temporary Help Services  \n2                            Claims Adjusting  \n3                          Commercial Banking  \n4                       Unclassified Industry  \n\n[5 rows x 131 columns]\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 72498 entries, 0 to 72497\nColumns: 131 entries, ID to NAICS_2022_6_NAME\ndtypes: float64(38), object(93)\nmemory usage: 72.5+ MB\nNone\n\n\nC:\\Users\\15PRO\\AppData\\Local\\Temp\\ipykernel_15088\\3175921105.py:3: DtypeWarning: Columns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(\"data/lightcast_job_postings.csv\")\n\n\n\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\n\ndf.drop(columns=columns_to_drop, inplace=True)\n\nprint(\"Updated DataFrame columns:\", df.columns.tolist())\n\nUpdated DataFrame columns: ['LAST_UPDATED_DATE', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2_NAME', 'NAICS3_NAME', 'NAICS4_NAME', 'NAICS5_NAME', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2_NAME', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n\n\n\nmissing_ratios = df.isnull().mean()\nranked_missing = missing_ratios.sort_values(ascending=False)\n\nprint(ranked_missing)\n\nhigh_missing = missing_ratios[missing_ratios &gt; 0.5]\n\nprint(high_missing)\n\nACTIVE_SOURCES_INFO     0.892163\nMAX_YEARS_EXPERIENCE    0.883721\nMAX_EDULEVELS           0.774959\nMAX_EDULEVELS_NAME      0.774959\nLIGHTCAST_SECTORS       0.754655\n                          ...   \nNAICS_2022_6_NAME       0.000607\nSOURCES                 0.000303\nSOURCE_TYPES            0.000303\nLAST_UPDATED_DATE       0.000303\nPOSTED                  0.000303\nLength: 118, dtype: float64\nACTIVE_SOURCES_INFO       0.892163\nMAX_EDULEVELS             0.774959\nMAX_EDULEVELS_NAME        0.774959\nMAX_YEARS_EXPERIENCE      0.883721\nSALARY                    0.575050\nORIGINAL_PAY_PERIOD       0.553119\nSALARY_TO                 0.553119\nSALARY_FROM               0.553119\nLIGHTCAST_SECTORS         0.754655\nLIGHTCAST_SECTORS_NAME    0.754655\ndtype: float64\n\n\n\nimport missingno as msno\nimport matplotlib.pyplot as plt\n# Visualize missing data\nmsno.heatmap(df)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\ndf[\"SALARY\"].fillna(df[\"SALARY\"].median(), inplace=True)\n\n# Drop columns with &gt;50% missing values\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n\n\n\n\n\n\n\nC:\\Users\\15PRO\\AppData\\Local\\Temp\\ipykernel_15088\\1425958293.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[\"SALARY\"].fillna(df[\"SALARY\"].median(), inplace=True)\n\n\n\ndf.fillna(df.mean(numeric_only=True), inplace=True)\ndf.fillna(\"Unknown\", inplace=True)\n\n\n# Remove duplicates based on key columns\ndf = df.drop_duplicates(\n    subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"],\n    keep=\"first\"\n)\n\n\ndf.to_csv(\"data/clean_lightcast_job_postings.csv\",index=None)"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\nimport os\nfrom plotly.subplots import make_subplots\nimport warnings\nwarnings.filterwarnings('ignore')\n\nif not os.path.exists(\"figures\"):\n    os.makedirs(\"figures\")\n\ntheme_colors = px.colors.qualitative.G10\ntemplate = \"plotly_white\"\n\n\ndf = pd.read_csv(\"data/clean_lightcast_job_postings.csv\")\n\nprint(\"Dataset shape:\", df.shape)\nprint(\"\\nSalary statistics:\")\nprint(df['SALARY'].describe())\n\nDataset shape: (69198, 109)\n\nSalary statistics:\ncount     69198.000000\nmean     116806.493352\nstd       29426.450593\nmin       15860.000000\n25%      116300.000000\n50%      116300.000000\n75%      116300.000000\nmax      500000.000000\nName: SALARY, dtype: float64\n\n\n\nemployment_counts = df['EMPLOYMENT_TYPE_NAME'].value_counts().reset_index()\nemployment_counts.columns = ['Employment Type', 'Count']\n\nfiga = px.bar(employment_counts, x='Employment Type', y='Count', \n              title='Job Postings by Employment Type',\n              color='Employment Type', color_discrete_sequence=theme_colors,\n              template=template)\nfiga.update_layout(\n    xaxis_title=\"Employment Type\",\n    yaxis_title=\"Number of Postings\",\n    legend_title=\"Employment Type\",\n    font=dict(family=\"Arial, sans-serif\", size=12)\n)\nfiga.write_html(\"figures/job_postings_by_employment_type.html\")\nfiga.write_image(\"figures/job_postings_by_employment_type.png\")\nfiga.show()\n\n                                                \n\n\n\nsalary_df = df[df['SALARY'].notna() & (df['SALARY'] &gt; 0) & (df['SALARY'] &lt; 500000)]\n\nfigb = px.box(salary_df, x=\"CITY_NAME\", y=\"SALARY\", \n              title=\"Salary Distribution by City\",\n              color_discrete_sequence=theme_colors,\n              template=template)\n\n# Show only top 10 cities by median salary to make the visualization clearer\ntop_cities = salary_df.groupby('CITY_NAME')['SALARY'].median().nlargest(10).index.tolist()\nfigb = px.box(salary_df[salary_df['CITY_NAME'].isin(top_cities)], \n              x=\"CITY_NAME\", y=\"SALARY\", \n              title=\"Salary Distribution by Top 10 Cities\",\n              color=\"CITY_NAME\", color_discrete_sequence=theme_colors,\n              template=template)\nfigb.update_layout(\n    xaxis_title=\"City\",\n    yaxis_title=\"Salary ($)\",\n    showlegend=False,\n    font=dict(family=\"Arial, sans-serif\", size=12)\n)\nfigb.write_html(\"figures/salary_distribution_by_city.html\")\nfigb.write_image(\"figures/salary_distribution_by_city.png\")\nfigb.show()\n\n                                                \n\n\n\nremote_counts = df['REMOTE_TYPE_NAME'].value_counts().reset_index()\nremote_counts.columns = ['Remote Type', 'Count']\n\nfigc = px.pie(remote_counts, names='Remote Type', values='Count', \n              title='Distribution of Remote vs. On-Site Jobs',\n              color='Remote Type', color_discrete_sequence=theme_colors,\n              template=template)\nfigc.update_layout(\n    legend_title=\"Remote Status\",\n    font=dict(family=\"Arial, sans-serif\", size=12)\n)\nfigc.write_html(\"figures/remote_vs_onsite_distribution.html\")\nfigc.write_image(\"figures/remote_vs_onsite_distribution.png\")\nfigc.show()\n\n                                                \n\n\n\n# Convert date columns to datetime\ndate_columns = ['LAST_UPDATED_DATE', 'POSTED', 'EXPIRED', 'MODELED_EXPIRED']\nfor col in date_columns:\n    if col in df.columns:\n        df[col] = pd.to_datetime(df[col], errors='coerce')\n\ndf['POSTING_MONTH'] = df['POSTED'].dt.to_period('M').astype(str)\n\n\n# Create a time-based analysis of job postings\nmonthly_postings = df.groupby('POSTING_MONTH').size().reset_index(name='count')\nmonthly_postings['POSTING_MONTH'] = pd.to_datetime(monthly_postings['POSTING_MONTH'])\nmonthly_postings = monthly_postings.sort_values('POSTING_MONTH')\nmonthly_postings['POSTING_MONTH'] = monthly_postings['POSTING_MONTH'].dt.strftime('%Y-%m')\n\nfig1 = px.line(monthly_postings, x='POSTING_MONTH', y='count', \n               title='Monthly Job Posting Trends',\n               labels={'count': 'Number of Postings', 'POSTING_MONTH': 'Month'},\n               template=template)\nfig1.update_layout(\n    xaxis_title=\"Month\",\n    yaxis_title=\"Number of Job Postings\",\n    legend_title=\"Legend\",\n    font=dict(family=\"Arial, sans-serif\", size=12)\n)\nfig1.write_html(\"figures/monthly_job_posting_trends.html\")\nfig1.write_image(\"figures/monthly_job_posting_trends.png\")\nfig1.show()\n\n                                                \n\n\n\n# Employment Type Analysis\nemployment_counts = df['EMPLOYMENT_TYPE_NAME'].value_counts().reset_index()\nemployment_counts.columns = ['Employment Type', 'Count']\n\nfig2 = px.bar(employment_counts, x='Employment Type', y='Count', \n              title='Job Postings by Employment Type',\n              color='Employment Type', color_discrete_sequence=theme_colors,\n              template=template)\nfig2.update_layout(\n    xaxis_title=\"Employment Type\",\n    yaxis_title=\"Number of Postings\",\n    legend_title=\"Employment Type\",\n    font=dict(family=\"Arial, sans-serif\", size=12)\n)\nfig2.write_html(\"figures/job_postings_by_employment_type.html\")\nfig2.write_image(\"figures/job_postings_by_employment_type.png\")\nfig2.show()\n\n                                                \n\n\n\n\n# Remote Work Analysis with nicer formatting\nremote_counts = df['REMOTE_TYPE_NAME'].value_counts().reset_index()\nremote_counts.columns = ['Remote Type', 'Count']\n\nfig3 = px.pie(remote_counts, names='Remote Type', values='Count', \n              title='Distribution of Remote vs. On-Site Jobs',\n              color='Remote Type', color_discrete_sequence=theme_colors,\n              template=template)\nfig3.update_layout(\n    legend_title=\"Remote Status\",\n    font=dict(family=\"Arial, sans-serif\", size=12)\n)\nfig3.write_html(\"figures/remote_vs_onsite_distribution.html\")\nfig3.write_image(\"figures/remote_vs_onsite_distribution.png\")\nfig3.show()\n\n                                                \n\n\n\n# Salary Analysis\nsalary_df = df[df['SALARY'].notna() & (df['SALARY'] &gt; 0)]\n\n# Top cities by average salary (with at least 50 job postings)\ncity_salary = salary_df.groupby('CITY_NAME').agg(\n    avg_salary=('SALARY', 'mean'),\n    job_count=('SALARY', 'count')\n).reset_index()\n\ncity_salary_filtered = city_salary[city_salary['job_count'] &gt;= 50].sort_values('avg_salary', ascending=False).head(10)\n\nfig4 = px.bar(city_salary_filtered, x='CITY_NAME', y='avg_salary',\n              title='Top 10 Cities by Average Salary (Min. 50 Postings)',\n              text='job_count', color='avg_salary', color_continuous_scale='Viridis',\n              template=template)\nfig4.update_traces(texttemplate='%{text} jobs', textposition='outside')\nfig4.update_layout(\n    xaxis_title=\"City\",\n    yaxis_title=\"Average Salary ($)\",\n    coloraxis_showscale=False,\n    font=dict(family=\"Arial, sans-serif\", size=12)\n)\nfig4.write_html(\"figures/top_cities_by_avg_salary.html\")\nfig4.write_image(\"figures/top_cities_by_avg_salary.png\")\nfig4.show()\n\n                                                \n\n\n\n# Salary distribution by state\nstate_salary = salary_df.groupby('STATE_NAME').agg(\n    avg_salary=('SALARY', 'mean'),\n    median_salary=('SALARY', 'median'),\n    job_count=('SALARY', 'count')\n).reset_index()\n\nstate_salary_filtered = state_salary[state_salary['job_count'] &gt;= 100].sort_values('avg_salary', ascending=False)\n\nfig5 = px.bar(state_salary_filtered, x='STATE_NAME', y='avg_salary',\n              title='Average Salary by State (Min. 100 Postings)',\n              color='job_count', text='median_salary',\n              labels={'job_count': 'Number of Job Postings'},\n              color_continuous_scale='Viridis',\n              template=template)\nfig5.update_traces(texttemplate='$%{text:.0f} median', textposition='outside')\nfig5.update_layout(\n    xaxis_title=\"State\",\n    yaxis_title=\"Average Salary ($)\",\n    coloraxis_colorbar_title=\"Job Count\",\n    font=dict(family=\"Arial, sans-serif\", size=12)\n)\nfig5.write_html(\"figures/avg_salary_by_state.html\")\nfig5.write_image(\"figures/avg_salary_by_state.png\")\nfig5.show()\n\n                                                \n\n\n\n# Experience requirements analysis\nexp_df = df[df['MIN_YEARS_EXPERIENCE'].notna()]\n\nfig6 = px.histogram(exp_df, x='MIN_YEARS_EXPERIENCE',\n                   title='Distribution of Minimum Experience Requirements',\n                   color_discrete_sequence=theme_colors,\n                   template=template)\nfig6.update_layout(\n    xaxis_title=\"Minimum Years of Experience\",\n    yaxis_title=\"Number of Job Postings\",\n    bargap=0.1,\n    font=dict(family=\"Arial, sans-serif\", size=12)\n)\nfig6.write_html(\"figures/min_experience_distribution.html\")\nfig6.write_image(\"figures/min_experience_distribution.png\")\nfig6.show()\n\n                                                \n\n\n\n# Education level requirements vs. Salary\nedu_salary = df[df['SALARY'].notna() & (df['MIN_EDULEVELS_NAME'].notna())].groupby('MIN_EDULEVELS_NAME').agg(\n    avg_salary=('SALARY', 'mean'),\n    median_salary=('SALARY', 'median'),\n    job_count=('SALARY', 'count')\n).reset_index()\n\nedu_salary = edu_salary[edu_salary['job_count'] &gt;= 30].sort_values('avg_salary')\n\nfig7 = px.bar(edu_salary, x='MIN_EDULEVELS_NAME', y='avg_salary',\n              title='Average Salary by Minimum Education Level',\n              color='job_count', text='median_salary',\n              labels={'job_count': 'Number of Job Postings', 'MIN_EDULEVELS_NAME': 'Education Level'},\n              color_continuous_scale='Viridis',\n              template=template)\nfig7.update_traces(texttemplate='$%{text:.0f} median', textposition='outside')\nfig7.update_layout(\n    xaxis_title=\"Minimum Education Level\",\n    yaxis_title=\"Average Salary ($)\",\n    coloraxis_colorbar_title=\"Job Count\",\n    font=dict(family=\"Arial, sans-serif\", size=12)\n)\nfig7.write_html(\"figures/salary_by_education.html\")\nfig7.write_image(\"figures/salary_by_education.png\")\nfig7.show()\n\n                                                \n\n\n\n\n# Industry analysis\nif 'NAICS_2022_2_NAME' in df.columns:\n    industry_field = 'NAICS_2022_2_NAME'\nelse:\n    industry_field = 'NAICS2_NAME'\n\nindustry_counts = df[df[industry_field].notna()][industry_field].value_counts().reset_index()\nindustry_counts.columns = ['Industry', 'Count']\nindustry_counts = industry_counts.head(10)  # Top 10 industries\n\nfig8 = px.bar(industry_counts, x='Count', y='Industry', \n              title='Top 10 Industries by Job Posting Count',\n              orientation='h', color='Count', color_continuous_scale='Viridis',\n              template=template)\nfig8.update_layout(\n    xaxis_title=\"Number of Job Postings\",\n    yaxis_title=\"Industry\",\n    font=dict(family=\"Arial, sans-serif\", size=12),\n    yaxis={'categoryorder':'total ascending'}\n)\nfig8.write_html(\"figures/top_industries.html\")\nfig8.write_image(\"figures/top_industries.png\")\nfig8.show()\n\n                                                \n\n\n\n\n# Salary Box Plot by Remote Type\nfig9 = px.box(salary_df, x='REMOTE_TYPE_NAME', y='SALARY',\n              title='Salary Distribution by Remote Work Type',\n              color='REMOTE_TYPE_NAME', color_discrete_sequence=theme_colors,\n              template=template)\nfig9.update_layout(\n    xaxis_title=\"Remote Work Type\",\n    yaxis_title=\"Salary ($)\",\n    showlegend=False,\n    font=dict(family=\"Arial, sans-serif\", size=12)\n)\nfig9.write_html(\"figures/salary_by_remote_type.html\")\nfig9.write_image(\"figures/salary_by_remote_type.png\")\nfig9.show()\n\n                                                \n\n\n\n# Create a combined visualization: Salary distribution by employment type with average markers\nfig10 = px.box(salary_df, x='EMPLOYMENT_TYPE_NAME', y='SALARY',\n              title='Salary Distribution by Employment Type',\n              color='EMPLOYMENT_TYPE_NAME', color_discrete_sequence=theme_colors,\n              template=template)\n\nemp_salary_avg = salary_df.groupby('EMPLOYMENT_TYPE_NAME')['SALARY'].mean().reset_index()\nfor i, emp_type in enumerate(emp_salary_avg['EMPLOYMENT_TYPE_NAME']):\n    avg_salary = emp_salary_avg.loc[emp_salary_avg['EMPLOYMENT_TYPE_NAME'] == emp_type, 'SALARY'].values[0]\n    fig10.add_trace(\n        go.Scatter(\n            x=[emp_type],\n            y=[avg_salary],\n            mode='markers',\n            marker=dict(color='red', size=10, symbol='star'),\n            name=f'Average: ${avg_salary:.0f}'\n        )\n    )\n\nfig10.update_layout(\n    xaxis_title=\"Employment Type\",\n    yaxis_title=\"Salary ($)\",\n    showlegend=False,\n    font=dict(family=\"Arial, sans-serif\", size=12)\n)\nfig10.write_html(\"figures/salary_by_employment_type.html\")\nfig10.write_image(\"figures/salary_by_employment_type.png\")\nfig10.show()"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "The rapid adoption of Artificial intelligence (AI) and Machine Learning (ML) in business analytics and data science is transforming how industries operate. AI-driven technologies are automating key processes, particularly in reshaping job roles, enhancing decision-making, and Human Resource Management (HRM), talent acquisition, and workforce planning. This study aims to examine the most in-demand skills, evolving job descriptions, and industry hiring trends in 2024, helping professionals navigate the changing job market.\nKey trends that make this a crucial area of study include:\n\nThe increasing reliance on AI-powered HR analytics to optimize recruitment and performance evaluation\nThe growing demand for AI/ML expertise in data science and business analytics roles\nThe role of automation in redefining traditional job functions and skill requirements\n\nBy analyzing these trends, this research will provide valuable insights into the career outlook for business analytics professionals and the necessary skills for success in an AI-driven job market."
  },
  {
    "objectID": "introduction.html#introduction",
    "href": "introduction.html#introduction",
    "title": "Introduction",
    "section": "",
    "text": "The rapid adoption of Artificial intelligence (AI) and Machine Learning (ML) in business analytics and data science is transforming how industries operate. AI-driven technologies are automating key processes, particularly in reshaping job roles, enhancing decision-making, and Human Resource Management (HRM), talent acquisition, and workforce planning. This study aims to examine the most in-demand skills, evolving job descriptions, and industry hiring trends in 2024, helping professionals navigate the changing job market.\nKey trends that make this a crucial area of study include:\n\nThe increasing reliance on AI-powered HR analytics to optimize recruitment and performance evaluation\nThe growing demand for AI/ML expertise in data science and business analytics roles\nThe role of automation in redefining traditional job functions and skill requirements\n\nBy analyzing these trends, this research will provide valuable insights into the career outlook for business analytics professionals and the necessary skills for success in an AI-driven job market."
  },
  {
    "objectID": "introduction.html#literature-review",
    "href": "introduction.html#literature-review",
    "title": "Introduction",
    "section": "Literature Review",
    "text": "Literature Review\nRecent research highlights AI‚Äôs transformative role in HRM and workforce analytics. Basnet (2024) explores how AI-powered hiring systems are improving recruitment accuracy, reducing biases, and enabling predictive workforce planning. AI‚Äôs ability to analyze large datasets allows HR professionals to identify optimal candidates and streamline hiring processes.\nMoreover, AI-driven tools in business analytics are influencing hiring trends. Companies are increasingly prioritizing AI/ML expertise when recruiting data scientists and business analysts. However, Basnet (2024) also highlights challenges, such as algorithmic bias, data privacy concerns, and ethical implications, that must be addressed to ensure fair hiring practices.\nThis study will further explore how AI is shaping job descriptions, salary trends, and career pathways in data science and business analytics, providing a roadmap for professionals to align their skills with evolving industry needs. Basnet (2024)\nThis study primarily explores how artificial neural networks (ANNs) and machine learning (ML) can model employee behavior and management interactions to drive economic advancement. While focused on HR dynamics, it indirectly highlights key trends in data science and ML. The use of shallow feed-forward ANNs to analyze non-linear relationships between job satisfaction, communication, and organizational outcomes underscores the demand for skills like predictive modeling, AI tool proficiency (e.g., TensorFlow/PyTorch), and statistical validation (e.g., linear regression). The emphasis on cross-industry data sampling suggests that roles in 2024 increasingly prioritize AI-driven decision-making and the ability to translate technical insights into actionable business strategies. Job descriptions now likely stress expertise in deploying ML solutions to solve real-world problems, such as predicting turnover or optimizing productivity, reflecting a shift toward hybrid skills in both analytics and domain-specific knowledge.\nIn terms of industry demand, the study‚Äôs multi-sector approach implies that data-heavy fields like finance, healthcare, and retail are aggressively hiring data scientists to enhance operational efficiency and employee management. For business analytics professionals, the career outlook ties closely to bridging technical and business realms‚Äîmastering tools like Python/SQL while interpreting data to uncover growth opportunities. As AI automates routine tasks (e.g., replacing dashboards with predictive reports), analysts must adapt by integrating ML into workflows. This evolution signals that future success hinges on continuous upskilling in AI/ML and cultivating collaborative mindsets to align data initiatives with organizational goals, ensuring relevance in a rapidly evolving job market.\nThe integration of Artificial Intelligence (AI) and Machine Learning (ML) into Business Intelligence (BI) and analytics has revolutionized how organizations analyze data and make strategic decisions. This research explores the transformative impact of AI technologies, such as predictive analytics, natural language processing (NLP), computer vision, and robotic process automation (RPA), on BI systems. By leveraging these advanced technologies, businesses can enhance their ability to process large datasets, automate repetitive tasks, and generate actionable insights. The study aims to highlight the opportunities and challenges associated with AI-driven BI, providing a comprehensive understanding of how these technologies can improve decision-making, operational efficiency, and customer experiences across various industries.\nRecent studies have emphasized the growing importance of AI in enhancing BI capabilities. Research by Davenport (2018) and Sun et al.¬†(2018) highlights the shift from descriptive to predictive and prescriptive analytics, enabled by AI and ML. NLP and text analytics have been particularly transformative, allowing businesses to extract insights from unstructured data like customer reviews and social media posts (Kaushik, 2022). Additionally, the integration of AI with IoT and Big Data has further expanded the scope of BI, enabling real-time analytics and more accurate forecasting (Eboigbe et al., 2023). Despite these advancements, challenges such as data quality, algorithmic transparency, and ethical considerations remain critical barriers to the widespread adoption of AI in BI (Rana et al., 2022). This paper contributes to the ongoing discourse by examining current trends, techniques, and future opportunities in AI-driven BI, offering valuable insights for both academia and industry."
  },
  {
    "objectID": "introduction.html#conclusion",
    "href": "introduction.html#conclusion",
    "title": "Introduction",
    "section": "Conclusion",
    "text": "Conclusion\nThe integration of AI and ML in HRM represents a transformative shift in how organizations manage human capital. While these technologies improve efficiency and decision-making, challenges such as algorithmic bias and ethical concerns must be addressed to ensure fair and transparent hiring processes. As businesses continue to embrace AI-driven HR solutions, professionals in business analytics and data science must acquire skills in AI ethics, workforce analytics, and automation strategies to stay competitive in the evolving job market.\nThis literature review highlights how AI is shaping the future of HRM, reinforcing the necessity for job seekers and HR professionals to adapt to technological advancements while maintaining a human-centric approach to workforce management (Lee 2024; Smith and Zhao 2023)."
  },
  {
    "objectID": "introduction.html#references",
    "href": "introduction.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\n\n\nLee, Cristina. 2024. ‚ÄúArtificial Neural Networks (ANNs) and Machine Learning (ML) Modeling Employee Behavior with Management Towards the Economic Advancement of Workers.‚Äù Sustainability 16: 9516. https://doi.org/10.3390/su16219516.\n\n\nSmith, John, and Li Zhao. 2023. ‚ÄúThe Impact of AI on Labor Markets.‚Äù Journal of Economic Perspectives 37 (2): 112‚Äì35. https://doi.org/10.1257/jep.37.2.112."
  }
]